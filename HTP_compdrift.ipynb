{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "from simulate import run_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Single Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique monomers\n",
    "N_MONs = 4\n",
    "\n",
    "# Molar ratios of each monomer\n",
    "# ex. if N_MONs = 4: [0.5, 0.25, 0.20, 0.05]\n",
    "MRs = [50, 25, 20, 5]\n",
    "\n",
    "# What model of copolymerization to use? (1) mayolewis (terminal) or (2) penultimate\n",
    "# NOTE FOR NOW ONLY MAYO-LEWIS IMPLEMENTED.\n",
    "#model = \"mayolewis\"\n",
    "\n",
    "# reactivity ratios of monomers, ex. for 4 monomers:\n",
    "#[r12, r13, r14]\n",
    "#[r21, r23, r24]\n",
    "#[r31, r32, r34]\n",
    "#[r41, r42, r43]\n",
    "RRs = ([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]])\n",
    "\n",
    "# % conversion targetted (0-1), i.e. how much of the monomer pool do you want to use\n",
    "conv = 0.5\n",
    "\n",
    "# average degree of polymerization (chain length) you are targetting at YOUR conversion, NOT at 100%.\n",
    "avgDP = 100\n",
    "\n",
    "# number of polymer chains to simulate\n",
    "N_CHAINs = 10000\n",
    "\n",
    "# Chain transfer % (0-1)\n",
    "# TODO: replace this with direct PDI control (not sure how)\n",
    "# NOTE TO SELF: for now just fix CTP such that PDI ~ 1.2, as thats roughly the control our RAFT synthesis gives.\n",
    "CTP = 0.05\n",
    "\n",
    "# cutoff DP of chains considered as polymers not oligomers that get \"purified\" out\n",
    "# set to 0 if you don't want to do any filtration\n",
    "PRUNE_OLIGOMERS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_simulation(N_MONs, N_CHAINs, MRs, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run Multiple Simulations\n",
    "\n",
    "Currently, various DPs are simulated - this can/should be changed to vary other things too, as well as instead of just simulating 4, a linspace between a max and min specifying the number of sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique monomers\n",
    "N_MONs = 4\n",
    "\n",
    "# Molar ratios of each monomer\n",
    "# ex. if N_MONs = 4: [0.5, 0.25, 0.20, 0.05]\n",
    "MRs = [50, 25, 20, 5]\n",
    "\n",
    "# reactivity ratios of monomers, ex. for 4 monomers:\n",
    "#[r12, r13, r14]\n",
    "#[r21, r23, r24]\n",
    "#[r31, r32, r34]\n",
    "#[r41, r42, r43]\n",
    "RRs = ([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]])\n",
    "\n",
    "# % conversion targetted (0-1), i.e. how much of the monomer pool do you want to use\n",
    "conv = 0.5\n",
    "\n",
    "# average degree of polymerization (chain length) you are targetting at YOUR conversion, NOT at 100%.\n",
    "avgDPs = [50, 75, 100, 125, 150, 175, 200, 225, 250]\n",
    "\n",
    "# number of polymer chains to simulate\n",
    "N_CHAINs = 10000\n",
    "\n",
    "# Chain transfer % (0-1)\n",
    "# TODO: replace this with direct PDI control (not sure how)\n",
    "# NOTE TO SELF: for now just fix CTP such that PDI ~ 1.2, as thats roughly the control our RAFT synthesis gives.\n",
    "CTP = 0.1\n",
    "\n",
    "# cutoff DP of chains considered as polymers not oligomers that get \"purified\" out\n",
    "# set to 0 if you don't want to do any filtration\n",
    "PRUNE_OLIGOMERS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for avgDP in avgDPs:\n",
    "    run_simulation(N_MONs, N_CHAINs, MRs, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Seq Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import csv\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import tee\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 25\n",
    "BIGGER_SIZE = 35\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sequence CSV files and set monomer properties\n",
    "Specify path and what monomers each label corresponds to here (by specifying Mw and HLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ALL SEQUENCE CSV FILES IN FOLDER SPECIFIED BY PATH\n",
    "\n",
    "path = \"outputs\"\n",
    "csv_files = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_files.append(os.path.join(path, file))\n",
    "csv_files = sorted(csv_files)\n",
    "print(\"Number of sequence files:\", len(csv_files))\n",
    "print(csv_files)\n",
    "\n",
    "### SET MOLECULAR WEIGHTS OF MONOMERS IN ORDER OF LABEL (labels are 1 indexed)\n",
    "Mw = [100.121,500,198.3,246.32]\n",
    "HLBs = [8.45, 11.42, 5.125, 18.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate general sequence statistics and average properties for all sequences by batch\n",
    "Output is a dataframe with column headers: [Batch Name\tNumSeqs\tAvg Mn\tAvg Mw\tPDI\tAvg DP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE AVERAGE DP, Mn, Mw & PDI OF ALL SEQUENCES\n",
    "\n",
    "names = []\n",
    "num_seqs = []\n",
    "avg_Mns = []\n",
    "avg_Mws = []\n",
    "PDIs = []\n",
    "avg_DPs = []\n",
    "seqs = []\n",
    "\n",
    "for m in tqdm_notebook(range(len(csv_files))):\n",
    "    seq = []\n",
    "\n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            seq.append(lines)\n",
    "    raw_seq = copy.deepcopy(seq)\n",
    "    seqs.append(raw_seq)\n",
    "    seqlen = np.zeros(i)\n",
    "    seqweight = np.zeros(i)\n",
    "    seqweight2 = np.zeros(i)\n",
    "\n",
    "    for j in range(0,i):\n",
    "        seqlen[j] = len(seq[j])\n",
    "        for k in range(len(seq[j])):\n",
    "            seq[j][k] = Mw[int(seq[j][k])-1]\n",
    "        seqweight[j] = sum(seq[j])\n",
    "        seqweight2[j] = (sum(seq[j])**2)\n",
    "\n",
    "    AvgMw = sum(seqweight2)/sum(seqweight)\n",
    "    AvgMn = sum(seqweight)/len(seqweight)\n",
    "    PDI = AvgMw/AvgMn\n",
    "    DP = sum(seqlen)/len(seqlen)\n",
    "\n",
    "    names.append(csv_files[m].replace(path, '').replace('/', '').replace('.csv', ''))\n",
    "    num_seqs.append(i)\n",
    "    avg_Mns.append(AvgMn)\n",
    "    avg_Mws.append(AvgMw)\n",
    "    PDIs.append(PDI)\n",
    "    avg_DPs.append(DP)\n",
    "    \n",
    "d = {'Batch Name': names, 'NumSeqs': num_seqs, 'Avg Mn': avg_Mns, 'Avg Mw': avg_Mws, 'PDI': PDIs, 'Avg DP': avg_DPs}\n",
    "df_prop = pd.DataFrame(data=d)\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv output files of 'n' batches and convert to n-element pd dataframe\n",
    "dfs = []\n",
    "seq_lens = []\n",
    "\n",
    "for m in range(len(csv_files)):\n",
    "    seq = []\n",
    "    row_size = []\n",
    "    \n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            seq.append(lines)\n",
    "            row_size.append(len(lines))\n",
    "        df = pd.DataFrame(seq)\n",
    "        dfs.append(df)\n",
    "        seq_lens.append(row_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mon2mon level\n",
    "Intra-chain positional variance\n",
    "- visualize sequences simulated\n",
    "- hydropathy plots with different window sizes\n",
    "- specific segment pattern search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific segment pattern search\n",
    "b_no = 8\n",
    "s_no = 837\n",
    "\n",
    "oegma_counter = 0\n",
    "seg_len = 0\n",
    "seg_array = []\n",
    "\n",
    "for i in range(len(dfs[b_no].iloc[s_no])):\n",
    "    if dfs[b_no][i][s_no] == str(2):\n",
    "        back_counter = 0\n",
    "        forward_counter = 0\n",
    "        j = 1\n",
    "        k = 1\n",
    "        while i-j >= 0 and (dfs[b_no][i-j][s_no] == str(1) or dfs[b_no][i-j][s_no] == str(3)):\n",
    "            j += 1\n",
    "            back_counter += 1\n",
    "        while i+k <= len(dfs[b_no].iloc[s_no])-1 and (dfs[b_no][i+k][s_no] == str(1) or dfs[b_no][i+k][s_no] == str(3)):\n",
    "            k += 1\n",
    "            forward_counter += 1\n",
    "        if forward_counter > 1 and back_counter > 1:\n",
    "            seg_array.append(back_counter + forward_counter + 1)\n",
    "\n",
    "if len(seg_array) == 0:\n",
    "    print('0 patterns found.')\n",
    "else:\n",
    "    print('Number of Hydrophobic segments with 1 OEGMA: ' + str(len(seg_array)))\n",
    "    print('Length of Hydrophobic segments with 1 OEGMA: ' + str(seg_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = [1, 2, 3, 4, 1, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 3, 4, 4, 2, 1, 2, 4, None, None, None]\n",
    "sample = [1, 1, 1, 3, 4, 4, 4, 4, 1, 1, 2, 3, 1, 3, 2, 1, 1, 4, 2, 4, 1, 1, 2, 1, 3, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific segment pattern search mon2mon level (still working on it)\n",
    "oegma_counter = 0\n",
    "seg_len = 0\n",
    "seg_array = []\n",
    "pos_array = list()\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    if sample[i] == 2:\n",
    "        back_counter = 0\n",
    "        forward_counter = 0\n",
    "        j = 1\n",
    "        k = 1\n",
    "        while (sample[i-j] == 1 or sample[i-j] == 3) and i-j >= 0:\n",
    "            j += 1\n",
    "            back_counter += 1\n",
    "        while i+k <= len(sample)-1 and (sample[i+k] == 1 or sample[i+k] == 3):\n",
    "            k += 1\n",
    "            forward_counter += 1\n",
    "        if forward_counter > 1 and back_counter > 1:\n",
    "            seg_array.append(back_counter + forward_counter + 1)\n",
    "\n",
    "print(seg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SLIDING WINDOW ANALYSIS OF POLYMERS\n",
    "# Set window length:\n",
    "WIN_LENGTH = 10\n",
    "\n",
    "# create a new list bins, to replace amino acids by corresponding hydrophobicity over the whole sequence \n",
    "def translate(chars, HLBs):\n",
    "    bins = []\n",
    "    for i in range(len(chars)):\n",
    "        bins.append(HLBs[int(chars[i])-1])\n",
    "    return bins\n",
    "\n",
    "# iterate an iterable sequence by the number of size per time and create a list of sliding_Arrays for that\n",
    "def window( iterable, size ):\n",
    "    sliding_array=[]\n",
    "    iters = tee(iterable, int(size))\n",
    "    for i in range(1, int(size)):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    for each in zip(*iters):\n",
    "        sliding_array.append(list(each))\n",
    "    return sliding_array\n",
    "\n",
    "# create a dictionary to keep the medium coordinate and average value for each sliding window\n",
    "def seg_analysis(sliding_arrays,win_length):\n",
    "    pos_val={}  \n",
    "    int_pos = int(win_length) // 2 +1\n",
    "    for each in sliding_arrays:\n",
    "        ave_value=np.mean(each)\n",
    "        pos_val[int_pos]=ave_value\n",
    "        int_pos+=1\n",
    "    return pos_val\n",
    "\n",
    "#input a dictionary including positions and average value of a sliding arrays, output a plot\n",
    "def win_plot(pos_val, pro_name, win_length, inverse=False):\n",
    "    # sorted by key, return a list of tuples\n",
    "    lists = list(sorted(pos_val.items())) \n",
    "    # unpack a list of pairs into two tuples\n",
    "    x, y=zip(*lists)\n",
    "    # Create a Figure\n",
    "    fig =plt.figure(figsize=(8,8))\n",
    "    # Set up Axes\n",
    "    ax= fig.add_subplot(111)\n",
    "    if inverse:\n",
    "        plt.ylim((5,13))\n",
    "        plt.gca().invert_yaxis()\n",
    "    ax.scatter(x, y)\n",
    "    ax.plot(x, y)\n",
    "    #ax.set_xlim(0, 60)\n",
    "    ax.set(title= \"Hydropathy plot of \" + str(pro_name) + \" ,window length = \" + str(win_length), xlabel=\"Center AA in AAs window\", ylabel=\"Average Hydrophobicity/Window\")\n",
    "    plt.savefig(\"outputs/\" + str(pro_name) + \"_\" + str(win_length) + \".png\",transparent =True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ACTUAL SCRIPT.\n",
    "for m in tqdm_notebook(range(len(csv_files))):\n",
    "    \n",
    "    filename = csv_files[m].replace(path, '').replace('/', '').replace('.csv', '')\n",
    "\n",
    "    mat = list()\n",
    "    for seq in tqdm_notebook(seqs[m]):\n",
    "        bins = translate(seq, HLBs)\n",
    "        sliding_arrays = window(bins, WIN_LENGTH)\n",
    "        pos_val = seg_analysis(sliding_arrays, WIN_LENGTH)\n",
    "        lists = list(sorted(pos_val.items()))\n",
    "        x,y = zip(*lists)\n",
    "\n",
    "        mat.append(y)\n",
    "            \n",
    "    df = pd.DataFrame(mat)\n",
    "    #r\"outputs/HLB_%s.xlsx\"%filename\n",
    "    df.to_csv(r'outputs/%s_%s_%d.csv'% (filename,\"HLB\",int(WIN_LENGTH)),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 2\n",
    "sequence_num = 1982\n",
    "\n",
    "filename = csv_files[m].replace(path, '').replace('/', '').replace('.csv', '')\n",
    "i = 0\n",
    "for seq in tqdm_notebook(seqs[m]):\n",
    "    if i == sequence_num:\n",
    "        bins = translate(seq, HLBs)\n",
    "        sliding_arrays = window(bins, WIN_LENGTH)\n",
    "        pos_val = seg_analysis(sliding_arrays, WIN_LENGTH)\n",
    "        win_plot(pos_val, filename, WIN_LENGTH)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq level\n",
    "Inter-chain variance within a batch\n",
    "- Histogram of chemical heterogeneity: distribution around feed ratio\n",
    "- box-whisker sliding window\n",
    "- batch summed statistics (histogram)\n",
    "- Specific segment pattern seq2seq distribution (i.e. 1 hydrophilic mon in hydrophobic segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seq2Seq Inputs: ENTER HERE\n",
    "window_len = 10 #specifies which window length HLB data to be analyzed (must be in outputs file)\n",
    "batch_no = 9 #specifies batch number to be analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histogram with KDE fit of composition on each individual monomer chain\n",
    "Also get statistics for the plot above (peak height, stdev & KDE fit), calculate Full Width at Half Maximum (FWHM = 2*sqrt(2*ln(2))* stdev ~= 2.355*stdev ) & FWHM normalized by feeding fraction, then plot batch2batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histograms of composition on each individual monomer chain:\n",
    "\n",
    "N_MONS = 4 # number of unique monomers\n",
    "RUN_ONLY_SUBSET = False # set False if you want to run all sequences\n",
    "\n",
    "FWHMs = []\n",
    "FWHM_norms = []\n",
    "\n",
    "for m in range(len(csv_files)):\n",
    "    seq = []\n",
    "    \n",
    "    if RUN_ONLY_SUBSET:\n",
    "        if m not in subset_inds:\n",
    "            continue\n",
    "    \n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            seq.append(lines)\n",
    "            #print(lines)\n",
    "\n",
    "    seqlen = np.zeros(i)\n",
    "    seq_comp = np.zeros([i,4])\n",
    "\n",
    "    for j in range(0,i):\n",
    "        seqlen[j] = len(seq[j])\n",
    "        for k in range(4):\n",
    "            seq_comp[j][k] = seq[j].count(str(k+1))/seqlen[j]\n",
    "            \n",
    "    print(csv_files[m].replace(path, '').replace('/', '').replace('.csv', ''))\n",
    "    FWHM = np.zeros(N_MONS)\n",
    "    FWHM_norm = np.zeros(N_MONS)\n",
    "    for i in range(N_MONS):\n",
    "        #MMA_x, MMA_y = sns.distplot(seq_comp[:,0], label=\"MMA\").get_lines()[0].get_data()\n",
    "        FWHM[i] = 2.355*np.std(seq_comp[:,i])\n",
    "        FWHM_norm[i] = 2.355*np.std(seq_comp[:,i])/np.mean(seq_comp[:,i])\n",
    "    print(FWHM)\n",
    "    print(FWHM_norm)\n",
    "    FWHMs.append(FWHM)\n",
    "    FWHM_norms.append(FWHM_norm)\n",
    "\n",
    "    plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    sns.set_style(style='white') #style='white' or 'darkgrid'\n",
    "    plt.xlabel(\"Feeding monomer fraction\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    sns.distplot(seq_comp[:,0], label=\"MMA\")\n",
    "    sns.distplot(seq_comp[:,1], label=\"OEGMA500\")\n",
    "    sns.distplot(seq_comp[:,2], label=\"EHMA\")\n",
    "    sns.distplot(seq_comp[:,3], label=\"SPMA\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.cla()   # Clear axis\n",
    "    plt.clf()   # Clear figure\n",
    "\n",
    "    \"\"\" # (same plot but using plt instead of sns)\n",
    "    plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.xlabel(\"chain composition fraction\", fontsize=15)\n",
    "    #plt.ylabel(\"asdf\")\n",
    "    plt.hist(seq_comp[:,0], label=\"MMA\")\n",
    "    plt.hist(seq_comp[:,1], label=\"OEGMA500\")\n",
    "    plt.hist(seq_comp[:,2], label=\"EHMA\")\n",
    "    plt.hist(seq_comp[:,3], label=\"SPMA\")\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "FWHMs = np.array(FWHMs)\n",
    "FWHM_norms = np.array(FWHM_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get HLB files of a particular window length\n",
    "path = \"outputs\"\n",
    "hlb_csv_files = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\"HLB_%d.csv\"% (int(window_len))):\n",
    "        hlb_csv_files.append(os.path.join(path, file))\n",
    "hlb_csv_files = sorted(hlb_csv_files)\n",
    "print(\"Number of sequence files:\", len(hlb_csv_files))\n",
    "print(hlb_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sliding window analysis csv files and convert to pd dataframes\n",
    "dfs_hlb = []\n",
    "seq_lens_hlb = []\n",
    "batch_ind = batch_no - 1\n",
    "\n",
    "for m in range(len(hlb_csv_files)):\n",
    "    seq = []\n",
    "    row_size = []\n",
    "    \n",
    "    with open(hlb_csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            if i > 1:\n",
    "                seq.append(lines)\n",
    "                row_size.append(len(lines))\n",
    "        df = pd.DataFrame(seq)\n",
    "        dfs_hlb.append(df)\n",
    "        seq_lens_hlb.append(row_size)\n",
    "\n",
    "rows_size = len(dfs_hlb[batch_ind])\n",
    "cols_size = len(dfs_hlb[batch_ind].columns)\n",
    "\n",
    "rows_size = len(dfs_hlb[batch_ind])\n",
    "print(\"rows size:\", rows_size)\n",
    "cols_size = len(dfs_hlb[batch_ind].columns)\n",
    "print(\"cols size:\", cols_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Whisker Plot of Sliding Window Analaysis Data\n",
    "\n",
    "pos_data = list()\n",
    "for i in range(cols_size):\n",
    "    datacol = [int(float((y_))) for y_ in dfs_hlb[batch_ind][i] if str(y_) != '']\n",
    "    pos_data.append(datacol)\n",
    "                      \n",
    "fig = plt.figure(figsize =(15, 7))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(pos_data, whis=(0,100))\n",
    "plt.xlabel(\"Sequence position\")\n",
    "plt.ylabel(\"Window average HLB\")\n",
    "plt.xticks([])\n",
    "#plt.xticks(np.arange(0,cols_size, step=20)) #TODO: fix x axis marks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize data and save it to output csv.\n",
    "\n",
    "binarized = []\n",
    "for i in range(rows_size):\n",
    "    binarized_seq = []\n",
    "    for j in range(cols_size):\n",
    "        if dfs_hlb[batch_ind][j][i] == '':\n",
    "            binarized_seq.append(2)\n",
    "        elif int(float(dfs_hlb[batch_ind][j][i])) > 9:\n",
    "            binarized_seq.append(1)\n",
    "        elif int(float(dfs_hlb[batch_ind][j][i])) <= 9:\n",
    "            binarized_seq.append(0)\n",
    "    binarized.append(binarized_seq)\n",
    "\n",
    "binarized_df = pd.DataFrame(binarized)\n",
    "binarized_df.to_csv(hlb_csv_files[batch_ind] + '_binarized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hydrophilic and hydrophobic segments count\n",
    "hydrophob_li = list()\n",
    "hydrophil_li = list()\n",
    "for i in tqdm_notebook(range(rows_size)):\n",
    "    hydrophobl = np.zeros(cols_size)\n",
    "    hydrophilbl = np.zeros(cols_size)\n",
    "    counterpho = 0\n",
    "    counterphil = 0\n",
    "    for j in range(cols_size):\n",
    "        if binarized_df[j][i] == 0:\n",
    "            counterpho += 1\n",
    "            if counterphil > 0:\n",
    "                hydrophilbl[counterphil-1] += 1\n",
    "            counterphil = 0\n",
    "            continue\n",
    "        elif binarized_df[j][i] == 1:\n",
    "            counterphil += 1\n",
    "            if counterpho > 0:\n",
    "                hydrophobl[counterpho-1] += 1\n",
    "            counterpho = 0\n",
    "            continue\n",
    "        else:\n",
    "            if counterpho > 0:\n",
    "                hydrophobl[counterpho-1] += 1\n",
    "            if counterphil > 0:\n",
    "                hydrophilbl[counterphil-1] += 1\n",
    "            break\n",
    "    hydrophob_li.append(hydrophobl)\n",
    "    hydrophil_li.append(hydrophilbl)\n",
    "\n",
    "hydrophobic_df = pd.DataFrame(hydrophob_li)\n",
    "hydrophilic_df = pd.DataFrame(hydrophil_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrophobic_i = len(hydrophobic_df.columns)\n",
    "hydrophilic_i = len(hydrophilic_df.columns)\n",
    "graph1_phob = []\n",
    "graph1_phil = []\n",
    "\n",
    "# sum the hydrophobic counts\n",
    "for i in range(hydrophobic_i):\n",
    "    a = np.sum(hydrophobic_df[i])\n",
    "    graph1_phob.append(a)\n",
    "\n",
    "# sum the hydrophilic counts\n",
    "for i in range(hydrophilic_i):\n",
    "    b = np.sum(hydrophilic_df[i])\n",
    "    graph1_phil.append(b)\n",
    "    \n",
    "# go backwards from both until you find the first non-zero entry and truncate there\n",
    "for i in range(1,len(graph1_phob)):\n",
    "    if (graph1_phob[-i] != 0.0):\n",
    "        graph1_phob = graph1_phob[:-i]\n",
    "        break\n",
    "\n",
    "for i in range(1,len(graph1_phil)):\n",
    "    if (graph1_phil[-i] != 0.0):\n",
    "        graph1_phil = graph1_phil[:-i]\n",
    "        break\n",
    "\n",
    "# create x-axis for both\n",
    "x_phob_1 = np.zeros(len(graph1_phob))\n",
    "x_phil_1 = np.zeros(len(graph1_phil))\n",
    "\n",
    "for i in range(len(graph1_phob)):\n",
    "    x_phob_1[i] = i+1\n",
    "\n",
    "for i in range(len(graph1_phil)):\n",
    "    x_phil_1[i] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT hydrophobic segments\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(x_phob_1,graph1_phob, width = 1)\n",
    "plt.xlabel(\"segment length\")\n",
    "plt.ylabel(\"number of segments\")\n",
    "plt.title(\"Hydrophobic Segments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT hydrophilic segments\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(x_phil_1,graph1_phil, width = 1)\n",
    "plt.xlabel(\"segment length\")\n",
    "plt.ylabel(\"number of segments\")\n",
    "plt.title(\"Hydrophilic Segments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FULL HYDROPHOBIC DATASET (non-zero)\n",
    "phobic_length_data = []\n",
    "for i in range(len(graph1_phob)):\n",
    "    phobic_length_data.append([ y_ for y_ in list(hydrophobic_df[i]) if y_ != 0.0])\n",
    "        \n",
    "fig = plt.figure(figsize =(12, 7))\n",
    "#ax = fig.add_axes([0, 1, 2, 1])\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(phobic_length_data, whis=(0,100))\n",
    "plt.xlabel(\"Hydrophobic Segment Length\")\n",
    "plt.ylabel(\"Non-zero counts\")\n",
    "#plt.xticks([])\n",
    "#plt.xticks(np.arange(0,cols_size, step=20)) #TODO: fix x axis marks\n",
    "plt.show()\n",
    "\n",
    "#  just hydrophobic segment lengths up to 10\n",
    "phobic_length_data2 = []\n",
    "for i in range(12):\n",
    "    phobic_length_data2.append([ y_ for y_ in list(hydrophobic_df[i]) if y_ != 0.0])\n",
    "\n",
    "fig = plt.figure(figsize =(12, 7))\n",
    "#ax2 = fig.add_axes([0, 0, 2, 1])\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(phobic_length_data2, whis=(0,100))\n",
    "plt.xlabel(\"Hydrophobic Segment Length\")\n",
    "plt.ylabel(\"Non-zero counts\")\n",
    "#plt.xticks([])\n",
    "#plt.xticks(np.arange(0,cols_size, step=20)) #TODO: fix x axis marks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FULL HYDROphilic DATASET (non-zero)\n",
    "philic_length_data = []\n",
    "for i in range(len(graph1_phil)):\n",
    "    philic_length_data.append([ y_ for y_ in list(hydrophilic_df[i]) if y_ != 0.0])\n",
    "        \n",
    "fig = plt.figure(figsize =(12, 7))\n",
    "#ax = fig.add_axes([0, 1, 2, 1])\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(philic_length_data, whis=(0,100))\n",
    "plt.xlabel(\"Hydrophilic Segment Length\")\n",
    "plt.ylabel(\"Non-zero counts\")\n",
    "#plt.xticks([])\n",
    "#plt.xticks(np.arange(0,cols_size, step=20)) #TODO: fix x axis marks\n",
    "\n",
    "#  just hydrophilic segment lengths up to 10\n",
    "philic_length_data2 = []\n",
    "for i in range(12):\n",
    "    philic_length_data2.append([ y_ for y_ in list(hydrophilic_df[i]) if y_ != 0.0])\n",
    "\n",
    "fig = plt.figure(figsize =(12, 7))\n",
    "#ax2 = fig.add_axes([0, 0, 2, 1])\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(philic_length_data2, whis=(0,100))\n",
    "plt.xlabel(\"Hydrophilic Segment Length\")\n",
    "plt.ylabel(\"Non-zero counts\")\n",
    "#plt.xticks([])\n",
    "#plt.xticks(np.arange(0,cols_size, step=20)) #TODO: fix x axis marks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific segment pattern search (seq2seq level)\n",
    "b_no = batch_no\n",
    "\n",
    "oegma_counter = 0\n",
    "seg_len_list = []\n",
    "seg_array_b = list()\n",
    "seg_arr = []\n",
    "allseg_array = []\n",
    "\n",
    "for s_no in range(len(dfs[b_no])):\n",
    "    seg_arr = []\n",
    "    for i in range(len(dfs[b_no].iloc[s_no])):\n",
    "        if dfs[b_no][i][s_no] == str(2):\n",
    "            back_counter = 0\n",
    "            forward_counter = 0\n",
    "            j = 1\n",
    "            k = 1\n",
    "            while i-j >= 0 and (dfs[b_no][i-j][s_no] == str(1) or dfs[b_no][i-j][s_no] == str(3)):\n",
    "                j += 1\n",
    "                back_counter += 1\n",
    "            while i+k <= len(dfs[b_no].iloc[s_no])-1 and (dfs[b_no][i+k][s_no] == str(1) or dfs[b_no][i+k][s_no] == str(3)):\n",
    "                k += 1\n",
    "                forward_counter += 1\n",
    "            if forward_counter > 1 and back_counter > 1:\n",
    "                seg_arr.append(back_counter + forward_counter + 1)\n",
    "                allseg_array.append(back_counter + forward_counter + 1)\n",
    "    seg_len_list.append(len(seg_arr))\n",
    "    seg_array_b.append(seg_arr)\n",
    "\n",
    "#seg_array_b --> list of lengths of Hydrophobic segments with 1 OEGMA per sequence in specified batch\n",
    "#seg_len_list --> array of number of Hydrophobic segments with 1 OEGMA per sequence in specified batch\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzes specific segment search data\n",
    "Avg_NumSeg = np.mean(np.array(seg_len_list))\n",
    "StDev_NumSeg = np.std(np.array(seg_len_list))\n",
    "Avg_LenSeg = []\n",
    "StDev_LenSeg = []\n",
    "\n",
    "for i in range(len(seg_array_b)):\n",
    "    avg = np.mean(np.array(seg_array_b[i]))\n",
    "    sdev = np.std(np.array(seg_array_b[i]))\n",
    "    Avg_LenSeg.append(avg)\n",
    "    StDev_LenSeg.append(sdev)\n",
    "\n",
    "print(\"Average Number of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(Avg_NumSeg))\n",
    "print(\"StDev of Number of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(StDev_NumSeg))\n",
    "#Uncomment following lines for length data per sequence\n",
    "#print(\"Average lengths of Hydrophobic segments with 1 OEGMA per sequence in batch: \" + str(Avg_LenSeg))\n",
    "#print(\"StDev of lengths of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(StDev_LenSeg))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel(\"segment length\")\n",
    "plt.ylabel(\"# of segments\")\n",
    "plt.title(\"Hydrophobic Segments with 1 OEGMA\")\n",
    "plt.hist(allseg_array, bins=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch2batch level\n",
    "Average batch statistics variance\n",
    "- repeats (how random is the MC)\n",
    "- Compare full width at half maximum  normalized  by monomer feeding  fraction (nFWHM)  across batches\n",
    "- Compare hydropathy,  segment length  & specific  segment  pattern plots across batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot batch2batch variation (FWHM)\n",
    "Add 2D array obtained in previous cell to sub-set dataframe (sub_df), the plot a scatter with line of best fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    df_prop['FWHM_' + str(i)] = FWHM_norms[:,i]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "sns.set_style(style='white') #style='white' or 'darkgrid'\n",
    "ax = sns.regplot(x=\"Avg DP\", y=\"FWHM_0\", data=df_prop, label='MMA')\n",
    "ax = sns.regplot(x=\"Avg DP\", y=\"FWHM_1\", data=df_prop, label='OEGMA')\n",
    "ax = sns.regplot(x=\"Avg DP\", y=\"FWHM_2\", data=df_prop, label='EHMA') \n",
    "ax = sns.regplot(x=\"Avg DP\", y=\"FWHM_3\", data=df_prop, label='SPMA')\n",
    "ax.set_ylabel('FWHM')\n",
    "#ax.set(ylim=(0, 1))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
