{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "from simulate import run_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Single Simulation\n",
    "Commented out, uncomment to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONOMERS USED - leave as default if theoretical\n",
    "#mon_names = ['mon1', 'mon2', 'mon3', 'mon4', 'mon5']\n",
    "mon_names = ['MMA', 'EHMA', 'OEGMA500', 'SPMA', 'NHSMA', 'TMAMA']\n",
    "\n",
    "### SET MOLECULAR WEIGHTS OF MONOMERS IN ORDER OF LABEL (labels are 1 indexed)\n",
    "#Mw = [100.121,500,198.3,246.32, 104.15]\n",
    "Mw = [100.121, 198.3, 500, 246.32, 183.16, 207.70] #MMA, EHMA, OEGMA500, SPMA, NHSMA, TMAMA\n",
    "#HLBs = [8.45, 11.42, 5.125, 18.5, 4.865]\n",
    "HLBs = [8.45, 5.125, 11.42, 18.5, 10, 10] #MMA, EHMA, OEGMA500, SPMA, placeholder, placeholder\n",
    "\n",
    "# Molar ratios of each monomer\n",
    "# ex. if N_MONs = 4: [0.5, 0.25, 0.20, 0.05]\n",
    "MRs = [46,19,25,0,5,5]\n",
    "\n",
    "# Number of unique monomers - auatomatically calculated from MRs above\n",
    "N_MONs = len(MRs)\n",
    "\n",
    "# What model of copolymerization to use? (1) mayolewis (terminal) or (2) penultimate\n",
    "# NOTE FOR NOW ONLY MAYO-LEWIS IMPLEMENTED.\n",
    "#model = \"mayolewis\"\n",
    "\n",
    "# reactivity ratios of monomers, ex. for 4 monomers:\n",
    "#[r12, r13, r14]\n",
    "#[r21, r23, r24]\n",
    "#[r31, r32, r34]\n",
    "#[r41, r42, r43]\n",
    "# FULL TABLE BELOW (MMA, EHMA, OEGMA, NHSMA, SPMA, TMAMA)\n",
    "#RRs = ([[0.9, 1.3, 0.5, 1.1, 0.6], # MMA\n",
    "#        [0.4, 1.3, 0.6, 1.0, 1.0], # EHMA\n",
    "#        [0.7, 0.4, 0.6, 0.7, 0.8], # OEGMA\n",
    "#        [0.7, 1.6, 2.0, 0.6, 0.7], # NHSMA\n",
    "#        [1.2, 1.0, 1.5, 0.9, ?], # SPMA\n",
    "#        [1.3, 1.7, 2.0, 0.7, ?] # TMAMA\n",
    "#      ])\n",
    "RRs = ([[0.9, 1.3, 1.1, 0.5, 0.6], # MMA\n",
    "        [0.4, 1.3, 1.0, 0.6, 1.0], # EHMA\n",
    "        [0.7, 0.4, 0.7, 0.6, 0.8], # OEGMA\n",
    "        [1.2, 1.0, 1.5, 0.9, 0.0], # SPMA - note SPMA-TMAMA unknown, 0 placeholder.\n",
    "        [0.7, 1.6, 2.0, 0.6, 0.7], # NHSMA\n",
    "        [1.3, 1.7, 2.0, 0.0, 0.7], # TMAMA - note TMAMA - SPMA unknown, 0 placeholder.\n",
    "      ])\n",
    "\n",
    "# % conversion targetted (0-1), i.e. how much of the monomer pool do you want to use\n",
    "conv = 0.675\n",
    "\n",
    "# average degree of polymerization (chain length) you are targetting at YOUR conversion, NOT at 100%.\n",
    "avgDP = 225\n",
    "\n",
    "# number of polymer chains to simulate\n",
    "N_CHAINs = 100000\n",
    "\n",
    "# Chain transfer % (0-1)\n",
    "# TODO: replace this with direct PDI control\n",
    "CTP = 1\n",
    "\n",
    "# cutoff DP of chains considered as polymers not oligomers that get \"purified\" out\n",
    "# set to 0 if you don't want to do any filtration\n",
    "PRUNE_OLIGOMERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO USE THIS CODE:\n",
    "run_simulation(N_MONs, N_CHAINs, MRs, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Run Multiple Simulations\n",
    "\n",
    "Change the array you want to modify, then also change the array you are looping over in the loop below - be sure to also change what is actually plugged into the equation! \n",
    "\n",
    "Sources for Styrene RRs:\n",
    "- https://pubs.acs.org/doi/10.1021/acs.macromol.8b01526 (MMA)\n",
    "\n",
    "- https://link.springer.com/article/10.1007/s13233-011-1207-z (OEGMA, assume same for EHMA and SPMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONOMERS USED - leave as default if theoretical\n",
    "mon_names = ['mon1', 'mon2', 'mon3', 'mon4', 'mon5']\n",
    "\n",
    "# Number of unique monomers\n",
    "N_MONs = 4\n",
    "#N_MONs = [2,3,4,5]\n",
    "\n",
    "# Molar ratios of each monomer\n",
    "# ex. if N_MONs = 4: [0.5, 0.25, 0.20, 0.05]\n",
    "#MRs = [[70,30,0,0,0], [51,27,22,0,0], [50,25,20,5,0], [45,20,15,5,15]]\n",
    "# MRs = [[10, 65, 20, 5],[20, 55, 20, 5],[30, 45, 20, 5],[40, 35, 20, 5],[50, 25, 20, 5],[60, 15, 20, 5],[70, 5, 20, 5]]\n",
    "#MRs = [[10,25,60,5],[20,25,50,5],[30,25,40,5],[40,25,30,5],[50, 25, 20, 5],[60,25,10,5]]\n",
    "MRs = [[12,44,19,25], [42,38,11,9], [47,22,21,10],[26,23,41,10]]\n",
    "\n",
    "# reactivity ratios of monomers, ex. for 5 monomers:\n",
    "#[r12, r13, r14, r15]\n",
    "#[r21, r23, r24, r25]\n",
    "#[r31, r32, r34, r35]\n",
    "#[r41, r42, r43, r45]\n",
    "#[r51, r52, r53, r54]\n",
    "RRs = ([[1, 1, 1, 0.491],\n",
    "       [1, 1.09, 1.09, 0.53],\n",
    "       [1, 1.09, 1.09, 0.53],\n",
    "       [1, 1.09, 1.09, 0.53], \n",
    "       [0.697, 0.53, 0.53, 0.53]])\n",
    "\n",
    "# % conversion targetted (0-1), i.e. how much of the monomer pool do you want to use\n",
    "conv = 0.5\n",
    "\n",
    "# average degree of polymerization (chain length) you are targetting at YOUR conversion, NOT at 100%.\n",
    "avgDPs = [50, 100]\n",
    "#avgDP = 100\n",
    "\n",
    "# number of polymer chains to simulate\n",
    "N_CHAINs = 15000\n",
    "#N_CHAINs = [1000, 3000, 5000, 8000, 10000, 15000, 20000, 30000, 40000, 50000, 75000, 100000]\n",
    "\n",
    "# Chain transfer % (0-1)\n",
    "# TODO: replace this with direct PDI control\n",
    "CTP = 0.15\n",
    "\n",
    "# cutoff DP of chains considered as polymers not oligomers that get \"purified\" out\n",
    "# set to 0 if you don't want to do any filtration\n",
    "PRUNE_OLIGOMERS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO VARY N_CHAINs\n",
    "# for n in N_CHAINs:\n",
    "#   run_simulation(N_MONs, n, MR, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)\n",
    "\n",
    "# UNCOMMENT TO VARY MRs\n",
    "# for m in MRs:\n",
    "#     run_simulation(N_MONs, N_CHAINs, m, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)\n",
    "\n",
    "# UNCOMMENT TO VARY N_MONs\n",
    "# for n,m in zip(N_MONs, MRs):\n",
    "#        run_simulation(n, N_CHAINs, m, RRs, avgDP, conv, CTP, PRUNE_OLIGOMERS)\n",
    "\n",
    "# UNCOMMENT TO VARY DPs:\n",
    "for d in avgDPs:\n",
    "       run_simulation(N_MONs, N_CHAINs, MR, RRs, d, conv, CTP, PRUNE_OLIGOMERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Seq Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages for sequence analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import csv\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import csv\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import tee\n",
    "import re\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# this is important to allow us to save figs as editable .pdf\n",
    "# 42 is some magic number encoded into matplotlib for True Font type\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "new_rc_params = {'text.usetex': False, \"svg.fonttype\": 'none'}\n",
    "matplotlib.rcParams.update(new_rc_params)\n",
    "\n",
    "XUGROUP_IGOR_MACRO_SIZE = 22\n",
    "\n",
    "plt.rc('font', family='Helvetica', size=XUGROUP_IGOR_MACRO_SIZE)  # controls default text sizes\n",
    "plt.rc('axes', titlesize=XUGROUP_IGOR_MACRO_SIZE)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=XUGROUP_IGOR_MACRO_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=XUGROUP_IGOR_MACRO_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=XUGROUP_IGOR_MACRO_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=XUGROUP_IGOR_MACRO_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=XUGROUP_IGOR_MACRO_SIZE)  # fontsize of the figure title\n",
    "plt.rc('lines', markersize=10)\n",
    "plt.rc('lines', linewidth=2) # thicker lines to match Xu Group Igor Macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sequence CSV files and set monomer properties\n",
    "Specify path and what monomers each label corresponds to here (by specifying Mw and HLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ALL SEQUENCE CSV FILES IN FOLDER SPECIFIED BY PATH\n",
    "\n",
    "path = \"outputs\"\n",
    "csv_files = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_files.append(os.path.join(path, file))\n",
    "csv_files = sorted(csv_files)\n",
    "print(\"Number of sequence files:\", len(csv_files))\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate general sequence statistics and average properties for all sequences by batch\n",
    "Output is a dataframe with column headers: [Batch Name\tNC\tAvg Mn\tAvg Mw\tPDI\tAvg DP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE AVERAGE DP, Mn, Mw & PDI OF ALL SEQUENCES\n",
    "\n",
    "names = []\n",
    "num_seqs = []\n",
    "avg_Mns = []\n",
    "avg_Mws = []\n",
    "PDIs = []\n",
    "avg_DPs = []\n",
    "seqs = []\n",
    "\n",
    "for m in tqdm_notebook(range(len(csv_files))):\n",
    "    seq = []\n",
    "\n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            seq.append(lines)\n",
    "    raw_seq = copy.deepcopy(seq)\n",
    "    seqs.append(raw_seq)\n",
    "    seqlen = np.zeros(i)\n",
    "    seqweight = np.zeros(i)\n",
    "    seqweight2 = np.zeros(i)\n",
    "\n",
    "    for j in range(0,i):\n",
    "        seqlen[j] = len(seq[j])\n",
    "        for k in range(len(seq[j])):\n",
    "            seq[j][k] = Mw[int(seq[j][k])-1]\n",
    "        seqweight[j] = sum(seq[j])\n",
    "        seqweight2[j] = (sum(seq[j])**2)\n",
    "    \n",
    "    # calculating molecular weight of chain (number-average or weight-average),\n",
    "    # degree of polymerization (DP), and polydispersity index (PDI)\n",
    "    AvgMw = sum(seqweight2)/sum(seqweight)\n",
    "    AvgMn = sum(seqweight)/len(seqweight)\n",
    "    PDI = AvgMw/AvgMn\n",
    "    DP = sum(seqlen)/len(seqlen)\n",
    "    \n",
    "    # formatting general sequence statistics & average properties calculated as csv file\n",
    "    names.append(csv_files[m].replace(path, '').replace('/', '').replace('.csv', ''))\n",
    "    n_mons = []\n",
    "    MR1s = []\n",
    "    MR2s = []\n",
    "    MR3s = []\n",
    "    MR4s = []\n",
    "    MR5s = []\n",
    "    MR6s = []\n",
    "    for name in names:\n",
    "        try:\n",
    "            # n_mons, MR1, ... MRN, n_chains, DP, conv, CTP, Filt\n",
    "            num_vals = re.findall(r'\\d+', name)\n",
    "            n_mons.append(int(num_vals[0]))\n",
    "            MR1s.append(int(num_vals[1]))\n",
    "            MR2s.append(int(num_vals[2]))\n",
    "            if len(num_vals) > 8:\n",
    "                MR3s.append(int(num_vals[3]))\n",
    "            else:\n",
    "                MR3s.append(0)\n",
    "            if len(num_vals) > 9:\n",
    "                MR4s.append(int(num_vals[4]))\n",
    "            else:\n",
    "                MR4s.append(0)\n",
    "            if len(num_vals) > 10:\n",
    "                MR5s.append(int(num_vals[5]))\n",
    "            else:\n",
    "                MR5s.append(0)\n",
    "            if len(num_vals) > 11:\n",
    "                MR6s.append(int(num_vals[6]))\n",
    "            else:\n",
    "                MR6s.append(0)\n",
    "        except IndexError as err:\n",
    "            n_mons.append(4)\n",
    "            MR1s.append(0)\n",
    "            MR2s.append(0)\n",
    "            MR3s.append(0)\n",
    "            MR4s.append(0)\n",
    "            MR5s.append(0)\n",
    "            MR6s.append(0)\n",
    "    num_seqs.append(i)\n",
    "    avg_Mns.append(AvgMn)\n",
    "    avg_Mws.append(AvgMw)\n",
    "    PDIs.append(PDI)\n",
    "    avg_DPs.append(DP)\n",
    "    \n",
    "d = {'Batch Name': names, 'Mons': n_mons, mon_names[0]: MR1s, mon_names[1]: MR2s, mon_names[2]: MR3s, mon_names[3]: MR4s, mon_names[4]: MR5s, mon_names[5]: MR6s, 'NC': num_seqs, 'Avg Mn': avg_Mns, 'Avg Mw': avg_Mws, 'PDI': PDIs, 'Avg DP': avg_DPs}\n",
    "df_prop = pd.DataFrame(data=d)\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv output files of 'n' batches and convert to n-element pd dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv output files of 'n' batches and convert to n-element pd dataframe\n",
    "dfs = []\n",
    "seq_lens = []\n",
    "\n",
    "for m in range(len(csv_files)):\n",
    "    seq = []\n",
    "    row_size = [] \n",
    "    \n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        i = 0\n",
    "        for lines in csvFile:\n",
    "            i = i + 1\n",
    "            seq.append(lines)\n",
    "            row_size.append(len(lines))\n",
    "        df = pd.DataFrame(seq)\n",
    "        dfs.append(df)\n",
    "        seq_lens.append(row_size)\n",
    "\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compdrift analysis\n",
    "Synthesis plots such as compositional drift, monomer consumption etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot monomer consumption compared to feeding ratios\n",
    "\n",
    "for i, df in tqdm_notebook(enumerate(dfs), total=len(dfs)):\n",
    "    \n",
    "    # create a dictionary to store counts\n",
    "    counts = {}\n",
    "    for mon in range(1,N_MONs+1):\n",
    "        counts[mon] = 0\n",
    "    total_counts = 0\n",
    "\n",
    "    for col in tqdm_notebook(df, total=len(df.columns)):\n",
    "        # convert the dataframe from strings to integers\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # count the number of non-zero entries in the column\n",
    "        col_counts = df[col][df[col] > 0].value_counts()\n",
    "\n",
    "        # add the counts to the dictionary\n",
    "        for num, count in col_counts.items():\n",
    "            counts[num] += count\n",
    "            total_counts += count\n",
    "\n",
    "    # sort the dictionary by keys in ascending order\n",
    "    counts = dict(sorted(counts.items()))\n",
    "\n",
    "    # calculate the percentage of each number in the dataframe\n",
    "    percentages = {}\n",
    "    for num, count in counts.items():\n",
    "        percentages[num] = (count / total_counts) * 100\n",
    "\n",
    "    # print the percentages\n",
    "    print(df_prop.iloc[i]['Batch Name'])\n",
    "    for num, percentage in percentages.items():\n",
    "        print(f\"{mon_names[num-1]}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition Heterogeneity\n",
    "- mon2mon: visualize sequences simulated (TODO: make this prettier - get code from adv. attack notebook)\n",
    "- seq2seq: Plot histogram with KDE fit of composition variance per chain around feeding fraction\n",
    "- batch2batch: nFWHM to compare histograms between batches (normalized full width half maximum: (FWHM = 2*sqrt(2*ln(2))* stdev ~= 2.355*stdev ) & FWHM normalized by feeding fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### VISUALIZE SEQUENCE SIMULATED\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Do you want thin white line between each monomer?\n",
    "# White line (True) helps you count # monomers in a continuous segment better\n",
    "# No white line (False) is just prettier, easier to look at\n",
    "WHITE_LINE = False \n",
    "\n",
    "# pick the batch & sequences to plot\n",
    "batch_no = 2\n",
    "seq_no = 0\n",
    "num_seqs = 50\n",
    "\n",
    "chains = []\n",
    "for i in range(num_seqs):\n",
    "    chains.append([int(x) if x != None else 0 for x in dfs[batch_no].iloc[seq_no + i]])\n",
    "\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure\n",
    "plt.figure(num=None, figsize=(30, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# This CMAP is MMA, EHMA, OEGMA500, SPMA, Mon5 - as per RHPapp publication.\n",
    "CMAP = ['white', '#ba6fba', '#d24f38', '#3b3796', '#54aabc', '#ff7bac']\n",
    "# This CMAP is MMA, EHMA, OEGMA500, SPMA, NHSMA and TMAMA - as per Hilburg et al.\n",
    "CMAP = ['white', '#555454', '#d74d2f', '#5a7ee6', '#e3cb45', '#3aad97', '#7d57b8']\n",
    "\n",
    "if WHITE_LINE:\n",
    "    ax = sns.heatmap(chains, vmin=0, vmax=df_prop.iloc[batch_no]['Mons'], linewidth=0.1, xticklabels=False, yticklabels=False, square=True, cmap=CMAP[:(N_MONs+1)])\n",
    "else:\n",
    "    ax = sns.heatmap(chains, vmin=0, vmax=df_prop.iloc[batch_no]['Mons'], linewidth=0, xticklabels=False, yticklabels=False, square=True, cmap=CMAP[:(N_MONs+1)])\n",
    "cb = ax.collections[0].colorbar\n",
    "cb.set_ticks(np.arange(1,N_MONs+1))\n",
    "cb.set_ticklabels(mon_names[:N_MONs+1])\n",
    "\n",
    "plt.show()\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Histograms of composition on each individual monomer chain:\n",
    "\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "RUN_ONLY_SUBSET = False # set False if you want to run all sequences\n",
    "USE_TITLE = False # Set true if you want to add a plot label i.e. for labeling which plot is which\n",
    "PLOT_Y_AXIS_TOP_LIM = 20 # set the y-axis height\n",
    "############################\n",
    "\n",
    "FWHMs = []\n",
    "FWHM_norms = []\n",
    "\n",
    "# loop across each batch of polymers\n",
    "for m in range(len(csv_files)):\n",
    "    N_MONS = df_prop['Mons'][m] # number of unique monomers\n",
    "    seq = []\n",
    "    \n",
    "    if RUN_ONLY_SUBSET:\n",
    "        if m not in subset_inds:\n",
    "            continue\n",
    "    \n",
    "    with open(csv_files[m], mode = 'r') as file:\n",
    "        csvFile = csv.reader(file)\n",
    "        num_seqs = 0\n",
    "        for lines in csvFile:\n",
    "            num_seqs = num_seqs + 1\n",
    "            seq.append(lines)\n",
    "\n",
    "    seqlen = np.zeros(num_seqs)\n",
    "    seq_comp = np.zeros([num_seqs,N_MONS])\n",
    "\n",
    "    # this loop counts the composition distribution of each chain as a fraction\n",
    "    for j in range(0,num_seqs):\n",
    "        seqlen[j] = len(seq[j])\n",
    "        for k in range(N_MONS):\n",
    "            seq_comp[j][k] = seq[j].count(str(k+1))/seqlen[j]\n",
    "    \n",
    "    # Calculating full width half maximum (FWHM)\n",
    "    print(csv_files[m].replace(path, '').replace('/', '').replace('.csv', ''))\n",
    "    FWHM = np.zeros(5)\n",
    "    FWHM_norm = np.zeros(5)\n",
    "    for i in range(N_MONS):\n",
    "        FWHM[i] = 2.355*np.std(seq_comp[:,i])\n",
    "        FWHM_norm[i] = FWHM[i]/np.mean(seq_comp[:,i])\n",
    "    \n",
    "    FWHMs.append(FWHM)\n",
    "    FWHM_norms.append(FWHM_norm)\n",
    "    \n",
    "    # Composition Histogram plotting: figure setup\n",
    "    fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "        \n",
    "    # Composition Histogram plotting: main code\n",
    "    sns.set_style(style='white')\n",
    "    plt.xlabel(\"Feeding monomer fraction\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    if USE_TITLE:\n",
    "        plt.title(str(df_prop['NC'][m]))\n",
    "    sns.kdeplot(seq_comp[:,0], label=\"MMA\")\n",
    "    sns.kdeplot(seq_comp[:,1], label=\"OEGMA\")\n",
    "    if N_MONS > 2:\n",
    "        sns.kdeplot(seq_comp[:,2], label=\"EHMA\")\n",
    "    if N_MONS > 3:\n",
    "        sns.kdeplot(seq_comp[:,3], label=\"SPMA\")\n",
    "    if N_MONS == 5:\n",
    "        sns.kdeplot(seq_comp[:,4], label=\"Styrene\")\n",
    "    ax.spines[\"top\"].set_linewidth(1.5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "    ax.spines[\"left\"].set_linewidth(1.5)\n",
    "    ax.spines[\"right\"].set_linewidth(1.5)\n",
    "    ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,PLOT_Y_AXIS_TOP_LIM)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "    # uncomment line below to save figures:\n",
    "    plt.savefig('Figures/' + str(df_prop['Batch Name'][m] + '.svg'), format='svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.cla()   # Clear axis\n",
    "    plt.clf()   # Clear figure\n",
    "\n",
    "\n",
    "FWHMs = np.array(FWHMs)\n",
    "FWHM_norms = np.array(FWHM_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Normalized-FWHM plots to compare histograms between batches\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "N_MONS = 4 # number of monomers, from 2-5\n",
    "PARAM_2_VARY = \"Batch Name\" # i.e., 'Batch Name', 'NC', 'Avg Mn'\n",
    "DISCRETE = True # note: 2 settings, discrete vs continuous to use for diff. data types\n",
    "USE_TITLE = True # Set true if you want to add a plot label i.e. for labeling which plot is which\n",
    "############################\n",
    "\n",
    "for i in range(5):\n",
    "    df_prop['nFWHM_' + str(i)] = FWHM_norms[:,i]\n",
    "\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "sns.set_style(style='white') #style='white' or 'darkgrid'\n",
    "ax = sns.regplot(x=PARAM_2_VARY, y=\"nFWHM_0\", data=df_prop, fit_reg=DISCRETE, label='MMA')\n",
    "ax = sns.regplot(x=PARAM_2_VARY, y=\"nFWHM_1\", data=df_prop, fit_reg=DISCRETE, label='OEGMA')\n",
    "if N_MONS > 2:\n",
    "    ax = sns.regplot(x=PARAM_2_VARY, y=\"nFWHM_2\", data=df_prop, fit_reg=DISCRETE, label='EHMA') \n",
    "if N_MONS > 3:\n",
    "    ax = sns.regplot(x=PARAM_2_VARY, y=\"nFWHM_3\", data=df_prop, fit_reg=DISCRETE, label='SPMA')\n",
    "if N_MONS > 5:\n",
    "    ax = sns.regplot(x=PARAM_2_VARY, y=\"nFWHM_4\", data=df_prop, fit_reg=DISCRETE, label='Styrene')\n",
    "\n",
    "ax.set_ylabel('nFWHM')\n",
    "if USE_TITLE:\n",
    "    ax.set_title('DP300')\n",
    "ax.spines[\"top\"].set_linewidth(1.5)\n",
    "ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "ax.spines[\"left\"].set_linewidth(1.5)\n",
    "ax.spines[\"right\"].set_linewidth(1.5)\n",
    "ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.savefig('Figures/FWHM_AvgDP_DP300.svg', format='svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrophilic & Hydrophobic Segments\n",
    "- mon2mon: Visualize hydrophobic & hydrophilic segments along a chain?\n",
    "- seq2seq: box-whisker of avg'd per chain proerties (NOTE: we don't actually need the batch summed statistics (histogram) for this level - its only good to compare across levels)\n",
    "- batch2batch: lineplot of summed histograms (summed statistics) with 1 line for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLB_CUTOFF: determines what is considered hydrophobic and what is considered hydrophilic\n",
    "# Anything less than or equal to HLB_CUTOFF is considered hydrophobic.\n",
    "HLB_CUTOFF = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VISUALIZE HYDROPHLIC & HYDROPHOBIC SEGMENTS\n",
    "# go through each sequence specified and BINARIZE based on HLB_CUTOFF, then visualize.\n",
    "\n",
    "## mon2mon level: visualize hydrophobic & hydrophilic segments along a chain\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "# input parameters for specific chain\n",
    "batch_ind = 4\n",
    "seq_no = 0\n",
    "num_seqs = 10\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "# binarizing code\n",
    "cols_size = len(dfs[batch_ind].columns)\n",
    "binarized_chains = []\n",
    "for i in range(num_seqs):\n",
    "    binarized_seq = []\n",
    "    for j in range(cols_size):\n",
    "        this_mon = dfs[batch_ind][j][i]\n",
    "        if this_mon is None:\n",
    "            binarized_seq.append(2)\n",
    "        elif HLBs[int(this_mon)-1] <= HLB_CUTOFF:\n",
    "            binarized_seq.append(0)\n",
    "        else:\n",
    "            binarized_seq.append(1)\n",
    "    binarized_chains.append(binarized_seq)\n",
    "\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure\n",
    "plt.figure(num=None, figsize=(55, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.heatmap(binarized_chains, vmin=0, vmax=2, linewidth=0.2, xticklabels=False, yticklabels=False)\n",
    "plt.savefig('Figures/ProK_binarized.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEQ2SEQ HYDROPHOBIC AND HYDROPHILIC SEGMENTS (averaged per chain properties)\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "# input parameters for specific batch for seq2seq analysis\n",
    "\n",
    "b_no = 5 # select batch to analyze\n",
    "\n",
    "seg_len_2_plot = [1,2,3,5,7] # segment lengths to plot\n",
    "\n",
    "MAX_SEG_LEN = 60 # guess at upper bounded length for hydrophobic segment (magic number to be replaced)\n",
    "\n",
    "USE_TITLE = True # Set true if you want to add a plot label i.e. for labeling which plot is which\n",
    "\n",
    "############################\n",
    "\n",
    "rows_size = len(dfs[b_no])\n",
    "cols_size = len(dfs[b_no].columns)\n",
    "\n",
    "# initializing lists to record hydrophobic and hydrophilic segments.\n",
    "# hydrophob_li & hydrophil_li are lists of arrays each list represents a sequence.\n",
    "# each array represents the counts of segments of length of it's position index.\n",
    "# i.e. [0,5,4,3,1,0] --> 0 segments of length 0, 5 of length 1, 3 of length 3 etc.\n",
    "hydrophob_li = list()\n",
    "hydrophil_li = list()\n",
    "\n",
    "for i in tqdm_notebook(range(rows_size)):\n",
    "    hydrophobl = np.zeros(cols_size)\n",
    "    hydrophilbl = np.zeros(cols_size)\n",
    "    counterpho = 0\n",
    "    counterphil = 0\n",
    "    for j in range(cols_size):\n",
    "        if dfs[b_no][j][i] == None:\n",
    "            if counterpho > 0:\n",
    "                hydrophobl[counterpho-1] += 1\n",
    "            if counterphil > 0:\n",
    "                hydrophilbl[counterphil-1] += 1\n",
    "            break\n",
    "        elif HLBs[int(dfs[b_no][j][i])-1] <= HLB_CUTOFF:\n",
    "            counterpho += 1\n",
    "            if counterphil > 0:\n",
    "                hydrophilbl[counterphil-1] += 1\n",
    "            counterphil = 0\n",
    "            continue\n",
    "        else:\n",
    "            counterphil += 1\n",
    "            if counterpho > 0:\n",
    "                hydrophobl[counterpho-1] += 1\n",
    "            counterpho = 0\n",
    "            continue\n",
    "\n",
    "    hydrophob_li.append(hydrophobl)\n",
    "    hydrophil_li.append(hydrophilbl)\n",
    "    \n",
    "## IF THROWS ERROR CHANGE RANGE OF PHOB AND PHIL A-D\n",
    "\n",
    "phob_or_phil = ['HPHOB', 'HPHIL']\n",
    "\n",
    "for k in phob_or_phil:\n",
    "\n",
    "    # Hydrophobic Segments per chain Counting Code.\n",
    "    # sum each sequence's array into 1 sequence array for -phobic \n",
    "    # these arrays \n",
    "    summed_seg_length_counts = []\n",
    "    for j in range(len(seg_len_2_plot)):\n",
    "        summed_seg_length_counts.append(np.zeros(MAX_SEG_LEN)) # NOTE MAX_SEG_LEN IS A MAGIC NUMBER THAT NEEDS TO BE REPLACED\n",
    "\n",
    "    # loop through each array represented sequence\n",
    "    # sum the segment lengths counts - so you have sum across all chains\n",
    "    if k == 'HPHOB':\n",
    "        for i in range(len(hydrophob_li)):\n",
    "            for j in range(len(seg_len_2_plot)):\n",
    "                if hydrophob_li[i][seg_len_2_plot[j]] != 0:\n",
    "                    summed_seg_length_counts[j][int(hydrophob_li[i][seg_len_2_plot[j]])] += 1\n",
    "    else:\n",
    "        for i in range(len(hydrophil_li)):\n",
    "            for j in range(len(seg_len_2_plot)):\n",
    "                if hydrophil_li[i][seg_len_2_plot[j]] != 0:\n",
    "                    summed_seg_length_counts[j][int(hydrophil_li[i][seg_len_2_plot[j]])] += 1\n",
    "\n",
    "    # remove the 0 index\n",
    "    trunc_sum_seg_len_counts = []\n",
    "    for j in range(len(seg_len_2_plot)):\n",
    "        trunc_sum_seg_len_counts.append(summed_seg_length_counts[j][1:])\n",
    "\n",
    "    # Hydrophobic Segments per chain Plotting Code\n",
    "    # NOTE WE ARE DIVIDING BY NUM_SEQS --> TO GET AN AVERAGE PER CHAIN.\n",
    "    fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    if k == 'HPHOB':\n",
    "        plt.xlabel(\"Counts of hydrophobic segments of length X\")\n",
    "    else:\n",
    "        plt.xlabel(\"Counts of hydrophilic segments of length X\")\n",
    "    plt.ylabel(\"Average frequency per chain\")\n",
    "    sns.set_style(style = 'white')\n",
    "\n",
    "    for j in range(len(seg_len_2_plot)):\n",
    "        x_data = np.linspace(1, len(trunc_sum_seg_len_counts[j]), len(trunc_sum_seg_len_counts[j]))\n",
    "        y_data = trunc_sum_seg_len_counts[j]/df_prop['NC'][b_no]\n",
    "        label = str(seg_len_2_plot[j])\n",
    "        sns.scatterplot(x_data,y_data,label=label)\n",
    "\n",
    "        cubic_interploation_model = interp1d(x_data, y_data, kind = \"cubic\")\n",
    "\n",
    "        #popt, pcov = curve_fit(func, x_data, y_data)\n",
    "        sns.lineplot(np.linspace(x_data.min(), x_data.max(), 300), cubic_interploation_model(np.linspace(x_data.min(), x_data.max(), 300)))\n",
    "\n",
    "    ax.spines[\"top\"].set_linewidth(1.5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "    ax.spines[\"left\"].set_linewidth(1.5)\n",
    "    ax.spines[\"right\"].set_linewidth(1.5)\n",
    "    ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    #ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.xlim(1,25)\n",
    "    plt.ylim(0,0.4)\n",
    "    plt.legend(title='X = ', frameon=False)\n",
    "    if USE_TITLE:\n",
    "        plt.title(\"NC = \" + str(df_prop['NC'][b_no]))\n",
    "    if k == 'HPHOB':\n",
    "        plt.savefig('Figures/seq2seq_hydrophobic_NChains_'+ str(df_prop.iloc[:,7][b_no]) + '_DP300.svg', format='svg')\n",
    "    else:\n",
    "        plt.savefig('Figures/seq2seq_hydrophilic_NChains_'+ str(df_prop.iloc[:,7][b_no]) + '_DP300.svg', format='svg')\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH SUMMED STATISTICS FOR HYDROPHILIC & HYDROPHOBIC SEGMENTS\n",
    "x_phob_all = []\n",
    "x_phil_all = []\n",
    "graph_phob_all = []\n",
    "graph_phil_all = []\n",
    "for batch_ind in tqdm_notebook(range(len(csv_files))):\n",
    "\n",
    "    rows_size = len(dfs[batch_ind])\n",
    "    #print(\"rows size:\", rows_size)\n",
    "    cols_size = len(dfs[batch_ind].columns)\n",
    "    #print(\"cols size:\", cols_size)\n",
    "    \n",
    "    # count the hydrophilic and hydrophobic segments\n",
    "    hydrophob_li = list()\n",
    "    hydrophil_li = list()\n",
    "    for i in tqdm_notebook(range(rows_size)):\n",
    "        hydrophobl = np.zeros(cols_size)\n",
    "        hydrophilbl = np.zeros(cols_size)\n",
    "        counterpho = 0\n",
    "        counterphil = 0\n",
    "        for j in range(cols_size):\n",
    "            if dfs[batch_ind][j][i] == None:\n",
    "                if counterpho > 0:\n",
    "                    hydrophobl[counterpho-1] += 1\n",
    "                if counterphil > 0:\n",
    "                    hydrophilbl[counterphil-1] += 1\n",
    "                break\n",
    "            elif HLBs[int(dfs[batch_ind][j][i])-1] <= HLB_CUTOFF:\n",
    "                counterpho += 1\n",
    "                if counterphil > 0:\n",
    "                    hydrophilbl[counterphil-1] += 1\n",
    "                counterphil = 0\n",
    "                continue\n",
    "            else:\n",
    "                counterphil += 1\n",
    "                if counterpho > 0:\n",
    "                    hydrophobl[counterpho-1] += 1\n",
    "                counterpho = 0\n",
    "                continue\n",
    "\n",
    "        hydrophob_li.append(hydrophobl)\n",
    "        hydrophil_li.append(hydrophilbl)\n",
    "\n",
    "    hydrophobic_df = pd.DataFrame(hydrophob_li)\n",
    "    hydrophilic_df = pd.DataFrame(hydrophil_li)\n",
    "\n",
    "    # Sum the segment counts\n",
    "    graph1_phob = np.array(hydrophobic_df.sum(axis=0))\n",
    "    graph1_phil = np.array(hydrophilic_df.sum(axis=0))\n",
    "\n",
    "    # go backwards from both until you find the first non-zero entry and truncate there\n",
    "    # +1 as well (so really +2) so that you don't end on a weird uptick.\n",
    "    for i in range(1,len(graph1_phob)):\n",
    "        if (graph1_phob[-i] != 0.0):\n",
    "            graph1_phob = graph1_phob[:(-i+2)]\n",
    "            break\n",
    "\n",
    "    for i in range(1,len(graph1_phil)):\n",
    "        if (graph1_phil[-i] != 0.0):\n",
    "            graph1_phil = graph1_phil[:(-i+2)]\n",
    "            break\n",
    "\n",
    "            \n",
    "    # create x-axis for both\n",
    "    x_phob_1 = np.arange(1,len(graph1_phob)+1)\n",
    "    x_phil_1 = np.arange(1,len(graph1_phil)+1)\n",
    "    x_phob_all.append(x_phob_1)\n",
    "    x_phil_all.append(x_phil_1)\n",
    "    graph_phob_all.append(graph1_phob)\n",
    "    graph_phil_all.append(graph1_phil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH LEVEL PLOTTING CELL.\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "# input parameters for batch-level analysis\n",
    "\n",
    "PARAM_2_VARY = 'Mons' # name of whatever variable is you are trying to plot & analyze (i.e. legend labels)\n",
    "LEGEND_TITLE = True # if you have numerical legend headers i.e. different DPs or NCs set this to True\n",
    "\n",
    "############################\n",
    "\n",
    "# for plotting smooth curves\n",
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "# LINE PLOTS ACROSS BATCHES: HYDROPHOBIC (PLOTTING CODE)\n",
    "fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "sns.set_style(style='white') #can set style='white' or 'darkgrid' depending on preference\n",
    "plt.xlabel(\"Hydrophobic Segment Length\")\n",
    "plt.ylabel(\"Average frequency per chain\")\n",
    "#Comment following 2 lines to remove autolabelling\n",
    "# WE ARE NORMANLIZING BY NUM_SEQS!\n",
    "for i in range(len(csv_files)):\n",
    "    x_data = x_phob_all[i]\n",
    "    y_data = graph_phob_all[i]/df_prop['NC'][i]\n",
    "    sns.scatterplot(x_data, y_data, label=str(df_prop[PARAM_2_VARY][i]))\n",
    "    popt, pcov = curve_fit(func, x_data, y_data)\n",
    "    sns.lineplot(np.linspace(x_data.min(), x_data.max(), 300), func(np.linspace(x_data.min(), x_data.max(), 300), *popt))\n",
    "    #sns.lineplot(x_phob_all[i], graph_phob_all[i]/df_prop['NC'][i], label= str(int(df_prop['Avg DP'][i])))\n",
    "## Uncomment the following lines to manually label\n",
    "# sns.lineplot(x_phob_all[0], graph_phob_all[0]/df_prop['NC'][i], label=\"5 Monomers\")\n",
    "# sns.lineplot(x_phob_all[1], graph_phob_all[1]/df_prop['NC'][i], label=\"4 Monomers\")\n",
    "# sns.lineplot(x_phob_all[2], graph_phob_all[2]/df_prop['NC'][i], label=\"2 Monomers\")\n",
    "# sns.lineplot(x_phob_all[3], graph_phob_all[3]/df_prop['NC'][i], label=\"3 Monomers\")\n",
    "ax.spines[\"top\"].set_linewidth(1.5)\n",
    "ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "ax.spines[\"left\"].set_linewidth(1.5)\n",
    "ax.spines[\"right\"].set_linewidth(1.5)\n",
    "ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlim(1,15)\n",
    "plt.ylim(0,15)\n",
    "if LEGEND_TITLE:\n",
    "    plt.legend(title=PARAM_2_VARY, frameon=False)\n",
    "else:\n",
    "    plt.legend(frameon=False)\n",
    "plt.savefig('Figures_Editable/batchsum_hydrophobic_AvgDP.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "# LINE PLOTS ACROSS BATCHES: HYDROPHILIC (PLOTTING CODE)\n",
    "fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "sns.set_style(style='white') #style='white' or 'darkgrid'\n",
    "plt.xlabel(\"Hydrophilic Segment Length\")\n",
    "plt.ylabel(\"Average frequency per chain\")\n",
    "#Comment following 2 lines to remove autolabelling\n",
    "for i in range(len(csv_files)):\n",
    "    x_data = x_phil_all[i]\n",
    "    y_data = graph_phil_all[i]/df_prop['NC'][i]\n",
    "    sns.scatterplot(x_data, y_data, label=str(df_prop[PARAM_2_VARY][i]))\n",
    "    popt, pcov = curve_fit(func, x_data, y_data)\n",
    "    sns.lineplot(np.linspace(x_data.min(), x_data.max(), 300), func(np.linspace(x_data.min(), x_data.max(), 300), *popt))\n",
    "    #sns.lineplot(x_phil_all[i], graph_phil_all[i]/df_prop['NC'][i], label= str(int(df_prop['Avg DP'][i])))\n",
    "## Uncomment the following lines to manually label\n",
    "# sns.lineplot(x_phil_all[0], graph_phil_all[0]/df_prop['NC'][i], label=\"5 Monomers\")\n",
    "# sns.lineplot(x_phil_all[1], graph_phil_all[1]/df_prop['NC'][i], label=\"4 Monomers\")\n",
    "# sns.lineplot(x_phil_all[2], graph_phil_all[2]/df_prop['NC'][i], label=\"2 Monomers\")\n",
    "# sns.lineplot(x_phil_all[3], graph_phil_all[3]/df_prop['NC'][i], label=\"3 Monomers\")\n",
    "ax.spines[\"top\"].set_linewidth(1.5)\n",
    "ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "ax.spines[\"left\"].set_linewidth(1.5)\n",
    "ax.spines[\"right\"].set_linewidth(1.5)\n",
    "ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlim(1,15)\n",
    "plt.ylim(0,15)\n",
    "if LEGEND_TITLE:\n",
    "    plt.legend(title=PARAM_2_VARY, frameon=False)\n",
    "else:\n",
    "    plt.legend(frameon=False)\n",
    "plt.savefig('Figures/batchsum_hydrophilic_AvgDP.svg', format='svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Segment Search\n",
    "Customizable section to find specific pattern i.e. right now the implementation looks for hydrophobic segments containing 1 OEGMA as the hypothesis are that these segments are key for proton transport. Another example (not implemented) could be looking at the flanking regions of a specific monomer and analyzing the composition.\n",
    "- mon2mon: find patterns on a single chain\n",
    "- seq2seq: box-whisker of distribution of patterns per chain and batch summed statistics (histogram)\n",
    "- batch2batch: to compare across batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific segment pattern search in sequence (mon2mon level)\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "#defined by input parameters b_no and s_no\n",
    "b_no = 0\n",
    "s_no = 1\n",
    "\n",
    "############################\n",
    "\n",
    "#initializing seg_len and seg_array variables\n",
    "\n",
    "seg_len = 0 # length of segment with 1 OEGMA\n",
    "seg_array = [] # segment with 1 OEGMA\n",
    "\n",
    "# counting and recording number of segments with 1 oegma in given sequence\n",
    "for i in range(len(dfs[b_no].iloc[s_no])):\n",
    "    this_mon = dfs[b_no][i][s_no]\n",
    "    if this_mon == None:\n",
    "        break\n",
    "    elif int(this_mon) == 2:\n",
    "        back_counter = 0\n",
    "        forward_counter = 0\n",
    "        j = 1\n",
    "        k = 1\n",
    "        while (i-j >= 0) and (dfs[b_no][i-j][s_no] != None) and (HLBs[int(dfs[b_no][i-j][s_no])-1] <= HLB_CUTOFF):\n",
    "            j += 1\n",
    "            back_counter += 1\n",
    "        while (i+k <= len(dfs[b_no].iloc[s_no])-1) and (dfs[b_no][i+k][s_no] != None) and (HLBs[int(dfs[b_no][i+k][s_no])-1] <= HLB_CUTOFF):\n",
    "            k += 1\n",
    "            forward_counter += 1\n",
    "        if forward_counter > 1 and back_counter > 1:\n",
    "            seg_array.append(back_counter + forward_counter + 1)\n",
    "\n",
    "if len(seg_array) == 0:\n",
    "    print('0 patterns found.')\n",
    "else:\n",
    "    print('Number of Hydrophobic segments with 1 OEGMA: ' + str(len(seg_array)))\n",
    "    print('Length of Hydrophobic segments with 1 OEGMA: ' + str(seg_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific segment pattern search (seq2seq level)\n",
    "# This cell loops through all batches and does all calculations\n",
    "# NOTE: can be very slow if NC is very large.\n",
    "\n",
    "total_array = []\n",
    "total_seg_len = []\n",
    "total_seg_array = []\n",
    "\n",
    "#if taking too long to run, remove 100k file by changing line to:\n",
    "#for b_no in tqdm_notebook(range(1, len(csv_files))):\n",
    "for b_no in tqdm_notebook(range(len(csv_files))):\n",
    "    # initializing counting variables (similar to above cell: mon2mon level)\n",
    "    oegma_counter = 0\n",
    "    seg_len_list = []\n",
    "    seg_array_b = []\n",
    "    seg_arr = []\n",
    "    allseg_array = []\n",
    "\n",
    "    # counting and recording number of segments with 1 oegma per sequence in iterated batch\n",
    "    for s_no in tqdm_notebook(range(len(dfs[b_no]))):\n",
    "        seg_arr = []\n",
    "        for i in range(len(dfs[b_no].iloc[s_no])):\n",
    "            this_mon = dfs[b_no][i][s_no]\n",
    "            if this_mon == None:\n",
    "                break\n",
    "            elif int(this_mon) == 2:\n",
    "                back_counter = 0\n",
    "                forward_counter = 0\n",
    "                j = 1\n",
    "                k = 1\n",
    "                while (i-j >= 0) and (dfs[b_no][i-j][s_no] != None) and (HLBs[int(dfs[b_no][i-j][s_no])-1] <= HLB_CUTOFF):\n",
    "                    j += 1\n",
    "                    back_counter += 1\n",
    "                while (i+k <= len(dfs[b_no].iloc[s_no])-1) and (dfs[b_no][i+k][s_no] != None) and (HLBs[int(dfs[b_no][i+k][s_no])-1] <= HLB_CUTOFF):\n",
    "                    k += 1\n",
    "                    forward_counter += 1\n",
    "                if forward_counter > 1 and back_counter > 1:\n",
    "                    seg_arr.append(back_counter + forward_counter + 1)\n",
    "                    allseg_array.append(back_counter + forward_counter + 1)\n",
    "        seg_len_list.append(len(seg_arr))\n",
    "        seg_array_b.append(seg_arr)\n",
    "    \n",
    "    # append counts and segments for all sequence in iterated batch to larger array\n",
    "    total_array.append(allseg_array)\n",
    "    total_seg_len.append(seg_len_list)\n",
    "    total_seg_array.append(seg_array_b)\n",
    "\n",
    "#seg_array_b --> list of lengths of Hydrophobic segments with 1 OEGMA per sequence in specified batch\n",
    "#seg_len_list --> array of number of Hydrophobic segments with 1 OEGMA per sequence in specified batch\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequency of 5, 8, 10, 13 monomer length hydrophobic segments with 1 OEGMA per chain\n",
    "\n",
    "# input parameter for batch within which sequences are counted for hydrophobic segments\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "#defined by input parameters b_no\n",
    "b_no = 5\n",
    "\n",
    "num_a = 5 # select which lengths of segments to be averaged and plotted\n",
    "num_b = 8\n",
    "num_c = 10\n",
    "num_d = 13\n",
    "\n",
    "############################\n",
    "\n",
    "ARR_a = []\n",
    "ARR_b = []\n",
    "ARR_c = []\n",
    "ARR_d = []\n",
    "\n",
    "for seq in range(len(total_seg_array[b_no])):\n",
    "    entry_a = 0\n",
    "    entry_b = 0\n",
    "    entry_c = 0\n",
    "    entry_d = 0\n",
    "    for lens in range(len(total_seg_array[b_no][seq])):\n",
    "        if total_seg_array[b_no][seq][lens] == num_a:\n",
    "            entry_a += 1\n",
    "        elif total_seg_array[b_no][seq][lens] == num_b:\n",
    "            entry_b += 1\n",
    "        elif total_seg_array[b_no][seq][lens] == num_c:\n",
    "            entry_c += 1\n",
    "        elif total_seg_array[b_no][seq][lens] == num_d:\n",
    "            entry_d += 1\n",
    "    ARR_a.append(entry_a)\n",
    "    ARR_b.append(entry_b)\n",
    "    ARR_c.append(entry_c)\n",
    "    ARR_d.append(entry_d)\n",
    "    \n",
    "        \n",
    "data_a = np.zeros(max(ARR_a))\n",
    "for i in range(len(ARR_a)):\n",
    "    for j in range(max(ARR_a)):\n",
    "        if ARR_a[i] == j:\n",
    "            data_a[j] += 1\n",
    "            \n",
    "data_b = np.zeros(max(ARR_b))\n",
    "for i in range(len(ARR_b)):\n",
    "    for j in range(max(ARR_b)):\n",
    "        if ARR_b[i] == j:\n",
    "            data_b[j] += 1\n",
    "            \n",
    "data_c = np.zeros(max(ARR_c))\n",
    "for i in range(len(ARR_c)):\n",
    "    for j in range(max(ARR_c)):\n",
    "        if ARR_c[i] == j:\n",
    "            data_c[j] += 1\n",
    "            \n",
    "data_d = np.zeros(max(ARR_d))\n",
    "for i in range(len(ARR_d)):\n",
    "    for j in range(max(ARR_d)):\n",
    "        if ARR_d[i] == j:\n",
    "            data_d[j] += 1\n",
    "\n",
    "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.xlabel(\"Counts of hydrophobic with 1 OEGMA segments of length X\")\n",
    "plt.ylabel(\"Average Frequency per chain\")\n",
    "sns.set_style(style = 'white')\n",
    "sns.lineplot(x = np.array(np.linspace(0, len(data_a)-1, num = len(data_a))), y = data_a/df_prop['NC'][b_no], label = str(num_a))\n",
    "sns.lineplot(x = np.array(np.linspace(0, len(data_b)-1, num = len(data_b))), y = data_b/df_prop['NC'][b_no], label = str(num_b))\n",
    "sns.lineplot(x = np.array(np.linspace(0, len(data_c)-1, num = len(data_c))), y = data_c/df_prop['NC'][b_no], label = str(num_c))\n",
    "sns.lineplot(x = np.array(np.linspace(0, len(data_d)-1, num = len(data_d))), y = data_d/df_prop['NC'][b_no], label = str(num_d))\n",
    "ax.spines[\"top\"].set_linewidth(2)\n",
    "ax.spines[\"bottom\"].set_linewidth(2)\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "ax.spines[\"right\"].set_linewidth(2)\n",
    "ax.tick_params('both', length=10, width=2, which='major')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,0.9)\n",
    "plt.legend(title=\"X =\", frameon=False)\n",
    "plt.savefig('Figures/seq2seq_segsearch_DP'+str(df_prop['Avg DP'][b_no])+'.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzes specific segment search data (batch2batch level)\n",
    "\n",
    "###### PARAMS TO VARY ######\n",
    "\n",
    "# input parameters for batch-level analysis\n",
    "\n",
    "PARAM_2_VARY = 'Batch Name' # name of whatever variable is you are trying to plot & analyze (i.e. legend labels)\n",
    "LEGEND_TITLE = False # if you have numerical legend headers i.e. different DPs or NCs set this to True\n",
    "\n",
    "############################\n",
    "\n",
    "\n",
    "Avg_NumSeg = np.mean(np.array(seg_len_list))\n",
    "StDev_NumSeg = np.std(np.array(seg_len_list))\n",
    "Avg_LenSeg = []\n",
    "StDev_LenSeg = []\n",
    "\n",
    "for i in range(len(seg_array_b)):\n",
    "    if seg_array_b[i] != []:\n",
    "        avg = np.mean(np.array(seg_array_b[i]))\n",
    "        sdev = np.std(np.array(seg_array_b[i]))\n",
    "        Avg_LenSeg.append(avg)\n",
    "        StDev_LenSeg.append(sdev)\n",
    "\n",
    "print(\"Average Number of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(Avg_NumSeg))\n",
    "print(\"StDev of Number of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(StDev_NumSeg))\n",
    "#Uncomment following lines for length data per sequence\n",
    "#print(\"Average lengths of Hydrophobic segments with 1 OEGMA per sequence in batch: \" + str(Avg_LenSeg))\n",
    "#print(\"StDev of lengths of Hydrophobic segments with 1 Oegma per sequence in batch: \" + str(StDev_LenSeg))\n",
    "\n",
    "plt.cla()   # Clear axis\n",
    "plt.clf()   # Clear figure\n",
    "plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111)\n",
    "sns.set_style(style='white') #style='white' or 'darkgrid'\n",
    "plt.xlabel(\"Hydrophobic with 1 OEGMA Segment Length\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlim(0,65)\n",
    "sns.set_style(style = 'white')\n",
    "#Comment following lines to remove autolabelling\n",
    "for i in range(len(csv_files)):\n",
    "    sns.distplot(total_array[i], label=str(df_prop[PARAM_2_VARY][i]), hist = False, kde_kws={'bw':1})\n",
    "    #sns.distplot(total_array[i], label=str(int(df_prop.iloc[i]['Avg DP'])),hist = False, kde_kws={'bw':1})\n",
    "    plt.legend()\n",
    "ax.spines[\"top\"].set_linewidth(2)\n",
    "ax.spines[\"bottom\"].set_linewidth(2)\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "ax.spines[\"right\"].set_linewidth(2)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "## Uncomment to label manually\n",
    "#sns.distplot(total_array[0], label=\"5 Monomers\", hist=False, kde_kws={'bw':1})\n",
    "# sns.distplot(total_array[1], label=\"4 Monomers\",hist = False)\n",
    "# sns.distplot(total_array[2], label=\"2 Monomers\",hist = False)\n",
    "# sns.distplot(total_array[3], label=\"3 Monomers\",hist = False)\n",
    "# plt.legend()\n",
    "if LEGEND_TITLE:\n",
    "    plt.legend(title=PARAM_2_VARY, frameon=False)\n",
    "else:\n",
    "    plt.legend(frameon=False)\n",
    "plt.savefig('Figures/batchsum_segsearch_DP.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Analysis\n",
    "EXTRA VARIABLE: window_length (note window_length >= FILT otherwise you will encounter errors if you try average a window longer than the shortest chain in a batch)\n",
    "- mon2mon: sliding window on a single chain --> hydropathy plot\n",
    "- seq2seq: box-whisker plot showing statistics along the positions of a chain\n",
    "- batch2batch: seq2seq plot averaged over positions and compared across batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SLIDING WINDOW ANALYSIS OF POLYMERS\n",
    "# Set window length:\n",
    "WIN_LENGTH = 9\n",
    "\n",
    "# for monomer-level plot\n",
    "batch_num = 5\n",
    "sequence_num = 5\n",
    "\n",
    "# create a new list bins, to replace amino acids by corresponding hydrophobicity over the whole sequence \n",
    "def translate(chars, HLBs):\n",
    "    bins = []\n",
    "    for i in range(len(chars)):\n",
    "        bins.append(HLBs[int(chars[i])-1])\n",
    "    return bins\n",
    "\n",
    "# iterate an iterable sequence by the number of size per time and create a list of sliding_Arrays for that\n",
    "def window( iterable, size ):\n",
    "    sliding_array=[]\n",
    "    iters = tee(iterable, int(size))\n",
    "    for i in range(1, int(size)):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    for each in zip(*iters):\n",
    "        sliding_array.append(list(each))\n",
    "    return sliding_array\n",
    "\n",
    "# create a dictionary to keep the medium coordinate and average value for each sliding window\n",
    "def seg_analysis(sliding_arrays,win_length):\n",
    "    pos_val={}  \n",
    "    int_pos = int(win_length) // 2 +1\n",
    "    for each in sliding_arrays:\n",
    "        ave_value=np.mean(each)\n",
    "        pos_val[int_pos]=ave_value\n",
    "        int_pos+=1\n",
    "    return pos_val\n",
    "\n",
    "#input a dictionary including positions and average value of a sliding arrays, output a plot\n",
    "def win_plot(pos_val, win_length, xlim=None, figratio=None, inverse=False):\n",
    "    # sorted by key, return a list of tuples\n",
    "    lists = list(sorted(pos_val.items())) \n",
    "    # unpack a list of pairs into two tuples\n",
    "    x, y=zip(*lists)\n",
    "    # Create a Figure\n",
    "    fig = plt.figure(figsize=(5.4*1.4, 4*1.4))\n",
    "    # Set up Axes\n",
    "    ax= fig.add_subplot(111)\n",
    "    if inverse:\n",
    "        plt.ylim((5,13))\n",
    "        plt.gca().invert_yaxis()\n",
    "    np.savetxt(str(batch_num) + '_WIN' + str(WIN_LENGTH) + '.csv', np.transpose(np.vstack((x,y))), delimiter=',', header=\"x,y\")\n",
    "    ax.scatter(x, y)\n",
    "    ax.plot(x, y)\n",
    "    ax.axhline(y=HLB_CUTOFF, color='k', linestyle='--')\n",
    "    if xlim != None:\n",
    "        ax.set_xlim(0, xlim)\n",
    "    ax.set_ylim(5,14.5)\n",
    "    ax.set(xlabel=\"Central Monomer Sequence Position\", ylabel=\"Window Average HLB Value\")\n",
    "    ax.spines[\"top\"].set_linewidth(1.5)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "    ax.spines[\"left\"].set_linewidth(1.5)\n",
    "    ax.spines[\"right\"].set_linewidth(1.5)\n",
    "    ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "    plt.tight_layout()\n",
    "    #ax.set(title= \"Hydropathy plot of \" + str(pro_name) + \" ,window length = \" + str(win_length), xlabel=\"Center AA in AAs window\", ylabel=\"Average Hydrophobicity/Window\")\n",
    "    #plt.savefig('plot.eps', format='eps')\n",
    "    plt.savefig(\"Figures/slidingwindow_MMA_EHMA_\" + str(df_prop.iloc[batch_num]['MR1']) + \"_WinLength\" + str(WIN_LENGTH) + \"_DP300.pdf\",transparent = True)\n",
    "    plt.show()\n",
    "\n",
    "this_seq = [int(x) for x in dfs[batch_num].iloc[sequence_num] if x != None]\n",
    "bins = translate(this_seq, HLBs)\n",
    "sliding_arrays = window(bins, WIN_LENGTH)\n",
    "pos_val = seg_analysis(sliding_arrays, WIN_LENGTH)\n",
    "win_plot(pos_val, WIN_LENGTH, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get HLB files of a particular window length\n",
    "\n",
    "dfs_hlb = []\n",
    "seq_lens_hlb = []\n",
    "for d in tqdm_notebook(range(len(csv_files))):\n",
    "    mat = list()\n",
    "    for seq in tqdm_notebook(seqs[d]):\n",
    "        bins = translate(seq, HLBs)\n",
    "        sliding_arrays = window(bins, WIN_LENGTH)\n",
    "        pos_val = seg_analysis(sliding_arrays, WIN_LENGTH)\n",
    "        lists = list(sorted(pos_val.items()))\n",
    "        x,y = zip(*lists)\n",
    "\n",
    "        mat.append(y)\n",
    "    dfs_hlb.append(pd.DataFrame(mat))\n",
    "    seq_lens_hlb.append(row_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch2batch_arr = []\n",
    "for batch_ind in tqdm_notebook(range(len(csv_files))):\n",
    "\n",
    "    rows_size = len(dfs_hlb[batch_ind])\n",
    "    print(\"rows size:\", rows_size)\n",
    "    cols_size = len(dfs_hlb[batch_ind].columns)\n",
    "    print(\"cols size:\", cols_size)\n",
    "\n",
    "    # Box Whisker Plot of Sliding Window Analysis Data: Setup (Data Reduction)\n",
    "\n",
    "    pos_data = list()\n",
    "    datacol_array = np.zeros(5)\n",
    "    for i in range(cols_size):\n",
    "        datacol = [y_ for y_ in dfs_hlb[batch_ind][i] if y_ > 0]\n",
    "        datacol_array[4] += np.amax(np.array(datacol))\n",
    "        datacol_array[0] += np.amin(np.array(datacol))\n",
    "        datacol_array[2] += np.mean(np.array(datacol))\n",
    "        datacol_array[3] += np.percentile(np.array(datacol), 75)\n",
    "        datacol_array[1] += np.percentile(np.array(datacol), 25)\n",
    "        pos_data.append(datacol)\n",
    "    \n",
    "    batch2batch_arr.append(datacol_array/cols_size)\n",
    "\n",
    "    fig = plt.figure(figsize =(15, 7))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.boxplot(pos_data, whis=(0,100))\n",
    "    plt.xlabel(\"Sequence position\")\n",
    "    plt.ylabel(\"Window average HLB\")\n",
    "    plt.xticks([])\n",
    "    plt.savefig('Figures/boxwhisker_slidingwindow_MMA_EHMA_'+str(df_prop.iloc[batch_ind]['MR1'])+'_'+str(df_prop.iloc[batch_ind]['MR3'])+'.pdf')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for figure generation: Box Whisker Plot\n",
    "\n",
    "fig = plt.figure(figsize = (11, 6))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.boxplot(batch2batch_arr, whis=(0,100))\n",
    "ax.spines[\"top\"].set_linewidth(1.5)\n",
    "ax.spines[\"bottom\"].set_linewidth(1.5)\n",
    "ax.spines[\"left\"].set_linewidth(1.5)\n",
    "ax.spines[\"right\"].set_linewidth(1.5)\n",
    "ax.tick_params('both', length=10, width=1.5, which='major')\n",
    "plt.xlabel(\"MMA:EHMA Variance\")\n",
    "plt.ylabel(\"Window average HLB Value\")\n",
    "xtick_a = [1]\n",
    "xtick_b = [str(df_prop.iloc[0]['MR1'])+':'+str(df_prop.iloc[0]['MR3'])]\n",
    "for i in range(2,len(csv_files)+1):\n",
    "    xtick_a.append(i)\n",
    "    xtick_b.append(str(df_prop.iloc[i-1]['MR1'])+':'+str(df_prop.iloc[i-1]['MR3']))\n",
    "plt.xticks(xtick_a, xtick_b)\n",
    "plt.ylim(5,14.5)\n",
    "plt.savefig('Figures/boxwhisker_slidingwindow_NChains_DP300.pdf', bbox_inches='tight', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
